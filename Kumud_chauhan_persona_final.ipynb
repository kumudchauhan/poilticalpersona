{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XU2DOjqVYHc"
   },
   "source": [
    "### Capstone Project : Political Ideology persona \n",
    "#### Author : Kumud Chauhan\n",
    "#### Professor : Randi Griffin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOiPfkoU6Gxf"
   },
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6yTkFqw1SPr"
   },
   "source": [
    "In this assignment, we trained a political ideology persona. This persona reads the message/text and gives us a score that shows how much it is interested in this message. If the interest score is close to 0, it means the text is leaning towards Democrats and if it is close to 1, then the text is leaning towards Republicans.\n",
    " To train our political ideology persona, we used twitter dataset from Kaggle which contains 86460 tweets which are labeled as Republican or Democrats. (Data source: https://www.kaggle.com/kapastor/democratvsrepublicantweets#ExtractedTweets.csv) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERNH1yey3gFe"
   },
   "source": [
    "We perform several tasks in this assignment, which are as follows:\n",
    "\n",
    "\n",
    "1.   Train a persona that gives an interest score from text that may be of interest of a democrat persona.\n",
    "2.   Lift Analysis that shows change in interest scores when a word is deleted.\n",
    "3.   Populate a table that shows top 5 words that improves the interest score and worst 5 words that affects the scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w98ALboKt9uE"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zHaC2aJ1NHH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "zNBbjhjhrBzP",
    "outputId": "d609f15c-5082-4031-cb03-ea50b8cf1414"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2cacc7e7-51f4-4f2f-bc04-1936a44e3b29\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2cacc7e7-51f4-4f2f-bc04-1936a44e3b29\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ExtractedTweets.csv to ExtractedTweets.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "# data source: https://www.kaggle.com/kapastor/democratvsrepublicantweets#ExtractedTweets.csv\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(uploaded['ExtractedTweets.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "-LS4N24zt8Gj",
    "outputId": "74b957d8-dfdc-490e-c406-e7ce64948d9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how our data looks\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "oIAHOtE49NB2",
    "outputId": "e39595f8-0fc7-4832-c0d1-454120847b2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Party</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Democrat</th>\n",
       "      <td>42068</td>\n",
       "      <td>42068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republican</th>\n",
       "      <td>44392</td>\n",
       "      <td>44392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Handle  Tweet\n",
       "Party                    \n",
       "Democrat     42068  42068\n",
       "Republican   44392  44392"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for class bias\n",
    "df.groupby('Party').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sn2D-BmNicG3"
   },
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WA64b_GxLEaH"
   },
   "outputs": [],
   "source": [
    "# process the tweets for training the persona\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "   tweet = re.sub(r'http\\S+', '', tweet) #remove links\n",
    "   tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet) #remove all characters except letters\n",
    "   tweet = \" \".join(tweet_tokenizer.tokenize(tweet)) #join the clean text as string\n",
    "   return tweet \n",
    "\n",
    "# apply the function on raw data to get processed data\n",
    "df['clean'] = df['Tweet'].apply(clean_tweet)\n",
    "processed_df = df[df['clean'].apply(len) > 0]\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(processed_df['Party'])\n",
    "## Data selection for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split( processed_df['clean'], labels , test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pexWqhfO5vPn"
   },
   "source": [
    "## Training Political Ideology persona model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Vnjxg8T7rsr"
   },
   "source": [
    "This part is further divided into two parts in which we explore different methods/algorithms to perform this task and compare among them to choose the best model for further analysis of the project.\n",
    "### Part a: Training a Logistic regression based persona model \n",
    "In this part, we use traditional ML methods to train persona such as `tfidf` and logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LH-HB5sz_RTi",
    "outputId": "83165bbc-d5d4-47b0-c6e3-dc028ec857eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77549, 137068)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing using TfidfVectorizer, we use upto trigrams.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1,3),min_df = 3)\n",
    "X_train_tfidf = tf_idf_vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E6-0EA4WAFAR",
    "outputId": "2139eeaf-cf8b-4b0b-c023-e49f51caaa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.8045723569687826\n"
     ]
    }
   ],
   "source": [
    "### Interest scores predictions using Traditional ML method: Logistic Regression\n",
    "clf = LogisticRegression(C=2, max_iter=200).fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tf_idf_vectorizer.transform(X_test)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(\"Test accuracy\",(accuracy_score(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fK1jzMZz9xi8"
   },
   "source": [
    "We achieved 80.45 % accuracy on the test dataset.\n",
    "\n",
    "### Part b: \n",
    "In this part, we use deep learning methods to train persona such as `word embeddings` and LSTM neural network.\n",
    "First, we traina bideirectional LSTM model with random initilaization of embeddings and further we train LSTM model with twitter pre-trained `Glove embeddings`.\n",
    "### Training LSTM model with random initialized embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAD1spg9Ckgk"
   },
   "outputs": [],
   "source": [
    "MAXLEN= 50\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(25000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "x_train_seq_padded = keras.preprocessing.sequence.pad_sequences(x_train_seq, maxlen=MAXLEN)\n",
    "x_test_seq_padded = keras.preprocessing.sequence.pad_sequences(x_test_seq,maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "_WTQ4vlhGVvH",
    "outputId": "1c18f9f2-3cee-4d7f-8b88-c240fc687108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "152/152 [==============================] - 26s 169ms/step - loss: 0.6000 - accuracy: 0.6709\n",
      "Epoch 2/8\n",
      "152/152 [==============================] - 26s 170ms/step - loss: 0.3879 - accuracy: 0.8191\n",
      "Epoch 3/8\n",
      "152/152 [==============================] - 26s 172ms/step - loss: 0.3021 - accuracy: 0.8619\n",
      "Epoch 4/8\n",
      "152/152 [==============================] - 26s 173ms/step - loss: 0.2467 - accuracy: 0.8868\n",
      "Epoch 5/8\n",
      "152/152 [==============================] - 26s 174ms/step - loss: 0.2026 - accuracy: 0.9080\n",
      "Epoch 6/8\n",
      "152/152 [==============================] - 27s 175ms/step - loss: 0.1660 - accuracy: 0.9250\n",
      "Epoch 7/8\n",
      "152/152 [==============================] - 27s 176ms/step - loss: 0.1380 - accuracy: 0.9399\n",
      "Epoch 8/8\n",
      "152/152 [==============================] - 27s 177ms/step - loss: 0.1162 - accuracy: 0.9513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2172f38278>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### LSTM model\n",
    "lstm_model = keras.Sequential([ \n",
    "    keras.layers.Embedding(25000,100, input_length = MAXLEN),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(512)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(x_train_seq_padded, y_train, epochs=8, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ybkqOcKOHEtD",
    "outputId": "236659fe-4b2d-4fa3-9b74-39f495c1175a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of lstm_model 0.7773006558418274\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy of lstm_model\",lstm_model.evaluate(x_test_seq_padded, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnV9ZqbsIQWc"
   },
   "source": [
    "### LSTM model with pre-trained twitter embedding\n",
    "\n",
    "First, download and unzip the pre-trained embeddings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "eL5VGpqXkCj9",
    "outputId": "aa3a470d-6945-49d1-cdac-92fabdb8c146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-01 16:01:35--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2020-04-01 16:01:35--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
      "--2020-04-01 16:01:35--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  2.00MB/s    in 11m 42s \n",
      "\n",
      "2020-04-01 16:13:17 (2.07 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "! wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "! unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Lt2AaeEsH9Zy",
    "outputId": "f45ef9ea-21fa-4486-968c-0594fbf5ac7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "## using pre-trained glove embedding\n",
    "embeddings_index = {}\n",
    "f = open( 'glove.twitter.27B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    word_embeddings = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = word_embeddings \n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "# creating embedding matrix for the words that exists in our dataset \n",
    "# from the pre-trained glove embedding\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "IlxI5_ump7Pj",
    "outputId": "8f8d3fb1-5d94-4684-d780-b2e7f621b5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "152/152 [==============================] - 29s 194ms/step - loss: 0.6250 - accuracy: 0.6447\n",
      "Epoch 2/8\n",
      "152/152 [==============================] - 30s 196ms/step - loss: 0.4621 - accuracy: 0.7750\n",
      "Epoch 3/8\n",
      "152/152 [==============================] - 30s 196ms/step - loss: 0.3494 - accuracy: 0.8386\n",
      "Epoch 4/8\n",
      "152/152 [==============================] - 30s 195ms/step - loss: 0.2904 - accuracy: 0.8686\n",
      "Epoch 5/8\n",
      "152/152 [==============================] - 30s 197ms/step - loss: 0.2537 - accuracy: 0.8878\n",
      "Epoch 6/8\n",
      "152/152 [==============================] - 30s 198ms/step - loss: 0.2277 - accuracy: 0.8985\n",
      "Epoch 7/8\n",
      "152/152 [==============================] - 30s 199ms/step - loss: 0.2020 - accuracy: 0.9105\n",
      "Epoch 8/8\n",
      "152/152 [==============================] - 30s 199ms/step - loss: 0.1810 - accuracy: 0.9196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20a2b66780>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### LSTM model with pre-trained Glove embeddings \n",
    "lstm_glove_model = keras.Sequential([ \n",
    "    keras.layers.Embedding(len(tokenizer.word_index) + 1,\n",
    "                           100, \n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=MAXLEN\n",
    "                           ),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(512)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "lstm_glove_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_glove_model.fit(x_train_seq_padded, y_train, epochs=8, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_REmGE_1KE4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qZlGxlp1toer",
    "outputId": "5de97b77-f5d5-4c77-cd4a-62a036fc0048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of lstm_model with glove embeddings 0.8006266951560974\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy of lstm_model with glove embeddings\",lstm_glove_model.evaluate(x_test_seq_padded, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iv07e8rz-qgo"
   },
   "source": [
    "### Model comparision \n",
    "\n",
    "On comparing different methods, we conclude that both traditional and deep learning methods give similar performace on this dataset. Since, this dataset consists of tweets, both political as well as apolitical, we think 80% accuracy is not that bad. We expect to have a better model accuracy if we use a larger dataset. We emphasize that the same codebase can be adopted to any text based binary classification model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-GVLN-MASZb"
   },
   "source": [
    "### PART 1: Persona Score\n",
    " Here, we define persona score prediction functions for both logistic regression as well as LSTM based persona models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tf9XgaN_6Wg"
   },
   "outputs": [],
   "source": [
    "def persona_score_one_hot_models(model,text,tf_idf_vectorizer):\n",
    "    text_tfidf = tf_idf_vectorizer.transform([text])\n",
    "    interest_score = model.predict_proba(text_tfidf)\n",
    "    return interest_score[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Q0KggPkA1Rj"
   },
   "outputs": [],
   "source": [
    "def persona_score_LSTM(model, text, tokenizer):\n",
    "    x_seq = tokenizer.texts_to_sequences([text])\n",
    "    x_seq_padded = keras.preprocessing.sequence.pad_sequences(x_seq, MAXLEN)\n",
    "    interest_score = model.predict(x_seq_padded)\n",
    "    return interest_score[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGpJ0HRgQgVm"
   },
   "outputs": [],
   "source": [
    "### Here, we use following two example tweets from the twitter (link provided)\n",
    "## We use these examples for lift analysis and explaining results\n",
    "\n",
    "# https://twitter.com/SpeakerPelosi/status/1244295869152854018\n",
    "dem_tweet = \"The #CARESAct was just a down payment in the fight against the coronavirus. We can and will do more to help state & local governments as they fight this public health crisis.\"\n",
    "\n",
    "# https://twitter.com/senatemajldr/status/1217613653106679808\n",
    "rep_tweet = \"Democrats’ impeachment has been nakedly partisan from the beginning. Pelosi admits it was in the making years before events with Ukraine. Schumer says that whatever happens, if it helps him politically, it’s a “win-win.” They are playing political games with the Constitution.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKmgQiRiQlHc"
   },
   "outputs": [],
   "source": [
    "def predict_score(text):\n",
    "  return persona_score_LSTM(lstm_glove_model, text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F9xvYv-hRSre",
    "outputId": "0e45a731-34d5-4001-f214-f99e2ef5e28c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473714"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(rep_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dILYxEiYRbKN",
    "outputId": "849f14cc-faa1-4477-b1e8-566c93112c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4072026"
      ]
     },
     "execution_count": 186,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(dem_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97LwPcgdS9DM"
   },
   "source": [
    "The interest score predicted for the rep_tweet by the model  is 0.84 and 0.40  for the dem_tweet. This reflects that the model is performing well.\n",
    "\n",
    "As we already mentioned earlier that if a score of greater than 0.50  means that the tweet shows republican ideology and if the model score is less than 0.50, it shows democratic (left) ideology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gKxHUoNRs63"
   },
   "source": [
    "We generated the scores using both models, using same test message and found that this tweet got very less democrat interest score which is expected since we have taken a republican tweet. \n",
    "In next part, we will see which words can improve the score to make it democratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwZyeJmA--Zz"
   },
   "source": [
    "## Part 2: LIFT ANALYSIS\n",
    "In this part, we compute an alternative score after deleting the tokens iteratively. We compute the change with respect to the baseline score and record that token's contribution. We will use the same examples (used above) for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsB_OBHS_CCJ"
   },
   "outputs": [],
   "source": [
    "## message optimization pipeline\n",
    "def lift_analysis(predict_fn, text,print_baseline = True, print_alternative = True):\n",
    "    baseline = predict_score(text)\n",
    "    if print_baseline:\n",
    "      print(\"The baseline score for the given text is\", baseline)\n",
    "    tokens = text.lower().split()\n",
    "    lift_score = {}\n",
    "    for i in range(len(tokens)):\n",
    "      if tokens[i] in stop_words.ENGLISH_STOP_WORDS:\n",
    "        continue\n",
    "      subtokens = tokens[0:i]+tokens[i+1:len(tokens)]\n",
    "      updated_text = ' '.join(subtokens)\n",
    "      alternative = predict_score(updated_text)\n",
    "      if print_alternative:\n",
    "        print(\"Dropping '{}', updated score: {}\".format(tokens[i], alternative))\n",
    "      lift_score[tokens[i]] = round(alternative-baseline,2)\n",
    "    return lift_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "8MRHKC5cJMsG",
    "outputId": "40b8c38c-920f-487e-d9de-11e7a5fe2364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for the given text is 0.4072026\n",
      "Dropping '#caresact', updated score: 0.4072026014328003\n",
      "Dropping 'just', updated score: 0.37688830494880676\n",
      "Dropping 'payment', updated score: 0.5570924878120422\n",
      "Dropping 'fight', updated score: 0.49595290422439575\n",
      "Dropping 'coronavirus.', updated score: 0.4072026014328003\n",
      "Dropping 'help', updated score: 0.38538673520088196\n",
      "Dropping 'state', updated score: 0.34755393862724304\n",
      "Dropping '&', updated score: 0.4072026014328003\n",
      "Dropping 'local', updated score: 0.4402707517147064\n",
      "Dropping 'governments', updated score: 0.2475307732820511\n",
      "Dropping 'fight', updated score: 0.5116938948631287\n",
      "Dropping 'public', updated score: 0.5888792872428894\n",
      "Dropping 'health', updated score: 0.5408839583396912\n",
      "Dropping 'crisis.', updated score: 0.223998561501503\n"
     ]
    }
   ],
   "source": [
    "lift_scores = lift_analysis(predict_score, dem_tweet, print_baseline = True, \n",
    "                            print_alternative = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKtblb1nUo0T"
   },
   "source": [
    "The above democrat_tweet example shows how the updated score is shifting towards the republican if we delete words \"payment\", \"public\", \"health\" from the tweet. This shows that these tokens are important in the sentence to predict the score and if we drop such terms from the sentence then we can convert this tweet ro right wing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "1Ew7NQKVJeys",
    "outputId": "ef974d59-8dbc-4fab-f358-78fe4525ec13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for the given text is 0.8473714\n",
      "Dropping 'democrats’', updated score: 0.8473713994026184\n",
      "Dropping 'impeachment', updated score: 0.9993457198143005\n",
      "Dropping 'nakedly', updated score: 0.8473713994026184\n",
      "Dropping 'partisan', updated score: 0.9303543567657471\n",
      "Dropping 'beginning.', updated score: 0.5395645499229431\n",
      "Dropping 'pelosi', updated score: 0.456940621137619\n",
      "Dropping 'admits', updated score: 0.978834867477417\n",
      "Dropping 'making', updated score: 0.7624854445457458\n",
      "Dropping 'years', updated score: 0.7941723465919495\n",
      "Dropping 'events', updated score: 0.9983073472976685\n",
      "Dropping 'ukraine.', updated score: 0.11966124922037125\n",
      "Dropping 'schumer', updated score: 0.002879971405491233\n",
      "Dropping 'says', updated score: 0.9889532327651978\n",
      "Dropping 'happens,', updated score: 0.33020299673080444\n",
      "Dropping 'helps', updated score: 0.7244032025337219\n",
      "Dropping 'politically,', updated score: 0.9885335564613342\n",
      "Dropping 'it’s', updated score: 0.8473713994026184\n",
      "Dropping '“win-win.”', updated score: 0.8416639566421509\n",
      "Dropping 'playing', updated score: 0.7857041954994202\n",
      "Dropping 'political', updated score: 0.6508424282073975\n",
      "Dropping 'games', updated score: 0.42191922664642334\n",
      "Dropping 'constitution.', updated score: 0.8759411573410034\n"
     ]
    }
   ],
   "source": [
    "lift_scores = lift_analysis(predict_score, rep_tweet, print_baseline = True, \n",
    "                            print_alternative = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwiN01CgWegx"
   },
   "source": [
    "Above repulican tweet shows that if we delete the word 'impeachment', 'partisan', says' from the tweet then the model is more confident to predict that it is a republican tweet. However, if we delete the terms 'schumer', 'ukraine.'then the updated score is shifting a democratic party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKuNZm0fDZ-K"
   },
   "source": [
    "## PART 3: Representing top words that lift score positively and worst words that affects the persona score negatively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gZSgxWqBIQB"
   },
   "outputs": [],
   "source": [
    "# Print top 5 words that lifts the score\n",
    "def top_5_words_contributing_persona_score(text):\n",
    "    lift_score = lift_analysis(predict_score, text, print_baseline = False, \n",
    "                               print_alternative = False)\n",
    "    lift_df = pd.DataFrame([lift_score], columns=lift_score.keys())\n",
    "    lift_df = lift_df.T\n",
    "    lift_df.columns = ['lift_score']\n",
    "    return lift_df.sort_values(by=['lift_score'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ptbdw6Lgtb-q"
   },
   "outputs": [],
   "source": [
    "# Print worst 5 words that affects the score negatively\n",
    "def worst_5_words_affecting_persona_score(text):\n",
    "    lift_score = lift_analysis(predict_score, text, print_baseline = False, \n",
    "                               print_alternative = False)\n",
    "    lift_df = pd.DataFrame([lift_score], columns=lift_score.keys())\n",
    "    lift_df = lift_df.T\n",
    "    lift_df.columns = ['lift_score']\n",
    "    return lift_df.sort_values(by=['lift_score'], ascending=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBq4YukcXkN_"
   },
   "source": [
    "From the lift analysis, we observed which words are important in the tweet, that helps the model to predict the political party of the tweet. Now, we analyze what are the top 5 words that contributes positively as well as worst 5 words that contributes negatively towards the overall tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "eDqHmz95DjYo",
    "outputId": "355bf9f9-ff18-4853-8be0-324dce31b872"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lift_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>events</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impeachment</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politically,</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admits</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lift_score\n",
       "events              0.15\n",
       "impeachment         0.15\n",
       "politically,        0.14\n",
       "says                0.14\n",
       "admits              0.13"
      ]
     },
     "execution_count": 196,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " top_5_words_contributing_persona_score(rep_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sg8n8ZD5tqcI",
    "outputId": "ca241147-d846-4591-b71e-127f291f2636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lift_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>schumer</th>\n",
       "      <td>-0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ukraine.</th>\n",
       "      <td>-0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happens,</th>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>games</th>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pelosi</th>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lift_score\n",
       "schumer        -0.84\n",
       "ukraine.       -0.73\n",
       "happens,       -0.52\n",
       "games          -0.43\n",
       "pelosi         -0.39"
      ]
     },
     "execution_count": 215,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_5_words_affecting_persona_score(rep_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvbEijLlP-z9"
   },
   "source": [
    "From the above two tables generated on the republican tweet, we observe that the word `events', \"impeachment\" contributes maximum to improve the score or to make the tweet more republican leaning. As expected, the words \"schumer\", \"pelosi\" are affecting the score negatively as the tweet is shifting towards democrats(neutral) if we delete these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "QMQPrwqJIjOy",
    "outputId": "232e5327-3832-4bb0-c63f-a92d5febb722"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lift_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fight</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lift_score\n",
       "public         0.18\n",
       "payment        0.15\n",
       "health         0.13\n",
       "fight          0.10\n",
       "local          0.03"
      ]
     },
     "execution_count": 199,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " top_5_words_contributing_persona_score(dem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "d9OPTEZ6Ivdz",
    "outputId": "dbb9f791-5093-4db9-d516-0d4dfaefe30b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lift_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crisis.</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>governments</th>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lift_score\n",
       "crisis.           -0.18\n",
       "governments       -0.16\n",
       "state             -0.06\n",
       "just              -0.03\n",
       "help              -0.02"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_5_words_affecting_persona_score(dem_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFDpVS9GZok-"
   },
   "source": [
    "Similarly, from the above two tables, we observed that words \"public\", \"payment\", \"health\" are important words to contribute positively towards the interest score. If we delete these words, then the tweet shifted towards the republican. While if we delete the words \"crisis\", \"governments\" from the democratic tweet then the score drops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwyHulJvPomB"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "*   In this project, we explored both traditional and deep learning methods to train a poltical ideology persona.\n",
    "*  We observed that pre-trained twitter glove embeddings performs slightly better than randomly initialized word embeddings.\n",
    "*  Since the dataset also contained some neutral tweets such as congratulatory messages, festival or new year wishes etc, we believe that training on a more political biased dataset will lead to a better persona.\n",
    "* Since we used deep learning (specifically Bi-directional LSTM models) which capture the semantic meaning and the meaning of a word depends on the context in which the word appears, that's why we did not remove stopwords. If we remove stopwords we may lose the important information on which our sequence model works. That's why we have some common words in our top and worst words list.\n",
    "*  In lift analysis part, we dropped tokens iteratively and compute the change of score due to which we lose some contextual information (semantic, syntactic etc.)  as the sentence feeded to the LSTM model might be grammaticaly incorrect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VolaiSW9OvC5"
   },
   "source": [
    "### Future work\n",
    "\n",
    "\n",
    "*   In future, we would like to train persona on a much larger corpus including \n",
    "political speeches, reddit discussions, news articles as well as twitter data.\n",
    "Also, to improve interest score, we will try to use more complex classfier such as BERT. \n",
    "*   Further, there are many recent advancements in NLP such as text style transfer, through which we can make the changes in the message and convert it into a democratic tweet and vice-versa.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kumud_chauhan_persona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
